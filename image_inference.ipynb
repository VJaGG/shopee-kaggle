{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "sys.path.append(\"/home/data_normal/abiz/wuzhiqiang/wzq/shopee/code_v3/pytorch-image-models\")\n",
    "import timm\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import albumentations as A\n",
    "import torch.utils.data as data\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_arch=\"bert-base-multilingual-uncased\"\n",
    "root = \"/home/data_normal/abiz/wuzhiqiang/wzq/data/shopee-product-matching/test.csv\"\n",
    "test_path = \"/home/data_normal/abiz/wuzhiqiang/wzq/data/shopee-product-matching/test_images\"\n",
    "initial_checkpoint = \"/home/data_normal/abiz/wuzhiqiang/wzq/shopee/code_v3/result/fold-0/checkpoint/00054500_model.pth\"\n",
    "df = pd.read_csv(root)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2255846744</td>\n",
       "      <td>0006c8e5462ae52167402bac1c2e916e.jpg</td>\n",
       "      <td>ecc292392dc7687a</td>\n",
       "      <td>Edufuntoys - CHARACTER PHONE ada lampu dan mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3588702337</td>\n",
       "      <td>0007585c4d0f932859339129f709bfdc.jpg</td>\n",
       "      <td>e9968f60d2699e2c</td>\n",
       "      <td>(Beli 1 Free Spatula) Masker Komedo | Blackhea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4015706929</td>\n",
       "      <td>0008377d3662e83ef44e1881af38b879.jpg</td>\n",
       "      <td>ba81c17e3581cabe</td>\n",
       "      <td>READY Lemonilo Mie instant sehat kuah dan goreng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id                                 image       image_phash  \\\n",
       "0  test_2255846744  0006c8e5462ae52167402bac1c2e916e.jpg  ecc292392dc7687a   \n",
       "1  test_3588702337  0007585c4d0f932859339129f709bfdc.jpg  e9968f60d2699e2c   \n",
       "2  test_4015706929  0008377d3662e83ef44e1881af38b879.jpg  ba81c17e3581cabe   \n",
       "\n",
       "                                               title  \n",
       "0  Edufuntoys - CHARACTER PHONE ada lampu dan mus...  \n",
       "1  (Beli 1 Free Spatula) Masker Komedo | Blackhea...  \n",
       "2   READY Lemonilo Mie instant sehat kuah dan goreng  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 40\n",
    "batch_size = 4\n",
    "width, height = 640, 640\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "null_augment = A.Compose(\n",
    "    [A.Resize(width, height)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch_size = len(batch)\n",
    "    image = []\n",
    "    index = []\n",
    "    input_ids = []\n",
    "    token_type_ids = []\n",
    "    attention_mask = []\n",
    "    for r in batch:\n",
    "        image.append((r['image'] / 255.0 - mean) / std)\n",
    "        index.append(r['index'])\n",
    "        input_ids.append(r['items']['input_ids'])\n",
    "        token_type_ids.append(r['items']['token_type_ids'])\n",
    "        attention_mask.append(r['items']['attention_mask'])\n",
    "    \n",
    "    image = np.stack(image)\n",
    "    input_ids = torch.stack(input_ids)\n",
    "    token_type_ids = torch.stack(token_type_ids)\n",
    "    attention_mask = torch.stack(attention_mask)\n",
    "\n",
    "    image = image.transpose(0, 3, 1, 2)\n",
    "    image = torch.from_numpy(image).contiguous().float()\n",
    "\n",
    "    return {\n",
    "        'index': index,\n",
    "        'image': image,\n",
    "        'input_ids': input_ids,\n",
    "        'token_type_ids': token_type_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShopeeDataset(data.Dataset):\n",
    "    def __init__(self, df, augment=null_augment, bert_model_arch=bert_model_arch):\n",
    "        self.df = df\n",
    "        self.augment = augment\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(bert_model_arch)\n",
    "        texts = df['title'].fillna(\"NaN\").tolist()  # 所有标题生成的文本列表\n",
    "        self.encodings = self.tokenizer(\n",
    "            texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        posting_info = self.df.iloc[index]\n",
    "        title = posting_info.title\n",
    "        image_name = posting_info.image\n",
    "        image_path = os.path.join(test_path, image_name)\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = image.astype(np.float32)\n",
    "\n",
    "        items = {k: torch.tensor(v[index]) for k, v in self.encodings.items()}\n",
    "        \n",
    "        if self.augment:\n",
    "            augmented = self.augment(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        r = {\n",
    "            'index': index,\n",
    "            'image': image,\n",
    "            'items': items\n",
    "        }\n",
    "        return r\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __str__(self):\n",
    "        string = ''\n",
    "        string += '\\tlen     = %d\\n' % len(self)\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    \"\"\"Implement of large margin arc distance: :\n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "        s: norm of input feature\n",
    "        m: margin\n",
    "        cos(theta + m)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        s: float = 30.0,\n",
    "        m: float = 0.5,\n",
    "        easy_margin: bool = False,\n",
    "        smoothing: float = 0.0,\n",
    "    ):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, inputs, labels):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "        cosine = F.linear(F.normalize(inputs), F.normalize(self.weight)).float()\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "\n",
    "        # --------------------------- convert label to one-hot ---------------------------\n",
    "        one_hot = torch.zeros(cosine.size(), device=labels.device)\n",
    "        one_hot.scatter_(1, labels.view(-1, 1).long(), 1)\n",
    "        if self.smoothing > 0:\n",
    "            one_hot = (\n",
    "                1 - self.smoothing\n",
    "            ) * one_hot + self.smoothing / self.out_features\n",
    "\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShopeeImgNet(nn.Module):\n",
    "    def __init__(self, arch=\"efficientnet_b3\",\n",
    "                 dim=2048, num_classes=11014, dropout=0.0, pretrained=True):\n",
    "        super(ShopeeImgNet, self).__init__()\n",
    "        self.backbone = timm.create_model(arch, pretrained=pretrained)\n",
    "        final_in_features = self.backbone.classifier.in_features\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.backbone.global_pool = nn.Identity()\n",
    "        self.bn1 = nn.BatchNorm2d(final_in_features)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(final_in_features, dim)\n",
    "        self.bn2 = nn.BatchNorm1d(dim)\n",
    "\n",
    "        self.margin = ArcMarginProduct(in_features=dim,\n",
    "                                       out_features=num_classes)\n",
    "        self._init_params()\n",
    "    \n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn1.weight, 1)\n",
    "        nn.init.constant_(self.bn2.weight, 1)\n",
    "        nn.init.constant_(self.bn1.bias, 0)\n",
    "        nn.init.constant_(self.bn2.bias, 0)\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        feature = self.backbone(x)\n",
    "        feature = self.bn1(feature)\n",
    "        feature = self.dropout(feature)\n",
    "        feature = self.pooling(feature).view(x.size(0), -1)\n",
    "        feature = self.fc(feature)\n",
    "        feature = self.bn2(feature)\n",
    "        if labels is not None:\n",
    "            return self.margin(feature, labels)\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feat(net, valid_loader):\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        valid_num = 0\n",
    "        for t, batch in enumerate(valid_loader):\n",
    "            index = batch['index']\n",
    "            image = batch['image'].cuda()\n",
    "            feat = net(image)\n",
    "            features += [feat.detach().cpu()]\n",
    "            valid_num += len(index)\n",
    "        assert (valid_num == len(valid_loader.dataset))\n",
    "    features = torch.cat(features).cpu().numpy()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches(posting_ids, threshold, features, n_batches, min_indices=1):\n",
    "    assert len(posting_ids) == len(features)\n",
    "    sim_threshold = threshold / 100\n",
    "    y_pred = []\n",
    "    n_rows = features.shape[0]\n",
    "    bs = n_rows // n_batches\n",
    "    batches = []\n",
    "    for i in range(n_batches):\n",
    "        left = bs * i\n",
    "        right = bs * (i + 1)\n",
    "        if i == n_batches - 1:\n",
    "            right = n_rows\n",
    "        batches.append(features[left: right, :])\n",
    "    for batch in batches:\n",
    "        dot_product = batch @ features.T\n",
    "        selection = dot_product > sim_threshold\n",
    "        for j in range(len(selection)):\n",
    "            IDX = selection[j]  # 阈值之内的相似图片\n",
    "            if np.sum(IDX) < min_indices:\n",
    "                IDX = np.argsort(dot_product[j])[-min_indices:]\n",
    "            y_pred.append(posting_ids[IDX].tolist())\n",
    "    assert len(y_pred) == len(posting_ids)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ShopeeDataset(df)\n",
    "test_dataloader = data.DataLoader(\n",
    "    test_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ShopeeImgNet()\n",
    "net.to(device)\n",
    "state_dict = torch.load(initial_checkpoint, map_location=lambda storage, loc: storage)['state_dict']\n",
    "net.load_state_dict(state_dict,strict=False)\n",
    "net.eval()\n",
    "del state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = extract_feat(net, test_dataloader)\n",
    "features = F.normalize(torch.from_numpy(features)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "posting_ids = df['posting_id']\n",
    "y_pred = find_matches(posting_ids, threshold, features, n_batches=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['matches'] = y_pred\n",
    "df['matches'] = df['matches'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['posting_id','matches']].to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2255846744</td>\n",
       "      <td>test_2255846744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3588702337</td>\n",
       "      <td>test_3588702337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4015706929</td>\n",
       "      <td>test_4015706929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id          matches\n",
       "0  test_2255846744  test_2255846744\n",
       "1  test_3588702337  test_3588702337\n",
       "2  test_4015706929  test_4015706929"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('submission.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
